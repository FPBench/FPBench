\documentclass[main.tex]{subfiles}
\begin{document}

\section{Tools}
\label{sec:tools}

\name features
  a collection of compilers and measurement tools
  that operates in its common format, \core.
These tools can be a community resource,
  increasing interoperability as well as code reuse.
They also make it easier to write
  new floating-point analysis and transformation tools
  by automating what are currently
  common but tedious tasks.

\paragraph{\surface to \core}
The \core format faithfully preserves important program constructs,
  such as variable binding and operation ordering,
  while abstracting away details not relevant
  to floating-point semantics.
However, it is syntactically very different
  from some of the languages from which benchmarks might originate.
To make translation to \core from source languages
  like C, Fortran, and Matlab easier,
  \name provides the \surface format
  and a compiler from \surface to \core.
\surface is syntactically similar to imperative languages,
  in order to make translation of benchmarks as easy as possible.

\paragraph{\core to C}
Since C is a common implementation language for mathematical computations,
  \name provides a \core to C compiler.
We expect this to be especially useful for tools
  that improve the accuracy of floating-point expressions
  and want to return the more accurate expressions to users.
What's more, the \core to C compiler can also be used to make \core benchmarks
run in the many available C analysis tools.

\begin{comment}
\paragraph{Worst-case error estimation}
\name provides a tool to give bounds on
  the worst-case absolute errors of a \core program
  using an abstract interpretation based on interval analysis
  following the approach pioneered by Martel et~al.~\cite{fmics15}.
The error analysis is fast
  and applies to loops without the need for loop invariants,
  though specialized tools such as Rosa~\cite{DarulovaK14}
  and FPTaylor~\cite{fptaylor-fm15}
  provide tighter error bounds.
For tools that improve the accuracy of floating-point computations,
  the static error analysis is a way to compare
  the original and improved computation,
  while tools that optimize programs given accuracy bounds
  can use the static analysis to derive the accuracy bounds demanded.
\end{comment}

\paragraph{Average error estimation}
Average error is an important metric for floating-point programs,
  and \name provides a tool to statistically approximate it.
The statistical approach is necessary to produce accurate estimates
  of average error given the current state of the art.
The tool allows choosing between absolute, relative, and ULP error,
  including bits of error (computed as the logarithm of ULPs error).

We plan to continue developing community tools around the \name formats,
  especially tools for estimating the other measures of error
  described in Section~\ref{sec:measure}.

\end{document}
