\documentclass[main.tex]{subfiles}
\begin{document}

\section{Tools}
\label{sec:tools}

\name features
  a collection of compilers and measurement tools
  that operate on its common format.
These tools can be a community resource,
  increasing interoperability and code reuse.
They also make it easier to write
  new floating point analysis and transformation tools
  by automating what are currently
  common but tedious tasks.

\paragraph{\surface to \core}
The \surface format allows \name benchmarks
  to be faithfully translated from imperative languages
  such as C, Fortran, or Matlab.
However, for many analyses,
  the imperative nature of \surface
  makes it less suited for analysis and transformation.
\name provides a compiler from \surface to \core
  to centralize that task.
Tools that do not want the additional information
  available in a \surface representation of a benchmark
  can work only with \core benchmarks
  use this compiler to transform inputs to that format.

\paragraph{\core canonicalization}
The \core syntax allows multiple representations of the same benchmark
  thanks to the presence of \C{let} bindings and variadic arithmetic operators.
For tools that do not want to handle these additional features,
  the canonicalizer automatically inlines \C{let} bindings
  and reduces variadic operators to binary ones.
This makes a minimal \name tool very easy to write.

\paragraph{\core to C}
Since C is a common implementation language for mathematical computations,
  \name provides a \core to C compiler.
We expect this to be especially useful for tools
  that improve the accuracy of floating point expressions
  and want to return the improved expressions to users.
The \core to C compiler can also be used
  to run analyze \name benchmarks
  using the many available C analysis tools.

\paragraph{Worst-case error estimation}
\name provides a tool to give bounds on
  the worst-case absolute error of a \core program
  using an abstract interpretation based on interval analysis
  following the approach pioneered by Martel et~al.~\cite{martel-ai}.
The error analysis is fast
  and applies to loops without the need for loop invariants,
  though specialized tools such as Rosa~\cite{DarulovaK14}
  and FPTaylor~\cite{fptaylor-fm15}
  provide tighter error bounds.
For tools that improve the accuracy of floating point computations,
  the static error analysis is a way to compare
  the original and improved computation,
  while tools that optimize programs given accuracy bounds
  can use the static analysis to derive the accuracy bounds demanded.

\paragraph{Average error estimation}
Average error is a second important metric for floating point programs,
  and \name provides a tool to statistically approximate it.
The statistical approach is necessary to produce accurate estimates
  of average error given the current state of the art.
The average error estimate combines with worst-case error bounds
  to provide detailed information about the error behavior
  of a floating point program.

\end{document}
